{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9899772,"sourceType":"datasetVersion","datasetId":6081167}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip3 install nibabel","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import nibabel as nib\n\n# Example to load a single image\nimage_path = '/kaggle/input/brats-africa/PKG - BraTS-Africa/BraTS-Africa/95_Glioma/BraTS-SSA-00002-000/BraTS-SSA-00002-000-t2f.nii'\nimage_data = nib.load(image_path)\nimage_array = image_data.get_fdata()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.imshow(image_array[:, 92, :], cmap='gray')  # Replace slice_number with the slice you want to view\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport nibabel as nib\nimport torch\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport numpy as np\n\n\nclass AdaIN(nn.Module):\n    def __init__(self, in_channel, style_dim):\n        super().__init__()\n        self.norm = nn.InstanceNorm3d(in_channel)\n        self.style = nn.Linear(style_dim, in_channel * 2)\n\n    def forward(self, x, style):\n        # Generate gamma and beta from style\n        style = self.style(style).unsqueeze(2).unsqueeze(3).unsqueeze(4)\n        gamma, beta = style.chunk(2, 1)\n        # Normalize and apply gamma and beta\n        out = self.norm(x)\n        return gamma * out + beta\n\n\nclass MappingNetwork(nn.Module):\n    def __init__(self, latent_dim=512, style_dim=512, num_classes=2):\n        super().__init__()\n        self.shared = nn.Sequential(\n            nn.Linear(latent_dim + num_classes, latent_dim),\n            nn.LeakyReLU(0.2),\n            *[nn.Sequential(\n                nn.Linear(latent_dim, latent_dim),\n                nn.LeakyReLU(0.2)\n            ) for _ in range(7)]\n        )\n        self.to_style = nn.Linear(latent_dim, style_dim)\n\n    def forward(self, z, label):\n        label_onehot = torch.zeros(z.size(0), 2, device=z.device)\n        label_onehot.scatter_(1, label.unsqueeze(1), 1)\n        x = torch.cat([z, label_onehot], dim=1)\n        x = self.shared(x)\n        return self.to_style(x)\n\n\nclass Generator3D(nn.Module):\n    def __init__(self, latent_dim=512, style_dim=512, num_classes=2):\n        super().__init__()\n        self.mapping = MappingNetwork(latent_dim, style_dim, num_classes)\n        self.const = nn.Parameter(torch.randn(1, 512, 4, 4, 4))\n        self.conv1 = nn.Conv3d(512, 256, kernel_size=3, stride=1, padding=1)\n        self.ada1 = AdaIN(512, style_dim)\n        self.conv2 = nn.ConvTranspose3d(256, 128, kernel_size=4, stride=2, padding=1) \n        self.ada2 = AdaIN(256, style_dim)\n        self.conv3 = nn.ConvTranspose3d(128, 64, kernel_size=4, stride=2, padding=1) \n        self.ada3 = AdaIN(128, style_dim)\n        self.conv4 = nn.ConvTranspose3d(64, 32, kernel_size=4, stride=2, padding=1) \n        self.ada4 = AdaIN(64, style_dim)\n        self.conv5 = nn.ConvTranspose3d(32, 16, kernel_size=4, stride=2, padding=1)\n        self.ada5 = AdaIN(32, style_dim)\n        self.conv6 = nn.Conv3d(16, 16, kernel_size=3, stride=1, padding=1)  \n        self.conv7 = nn.ConvTranspose3d(16, 1, kernel_size=3, stride=1, padding=1) \n\n        self.activation = nn.LeakyReLU(0.2)\n        self.tanh = nn.Tanh()\n\n    def forward(self, z, label, noise_inject=True):\n        batch_size = z.size(0)\n        w = self.mapping(z, label)\n        x = self.const.expand(batch_size, -1, -1, -1, -1)\n\n        x = self.conv1(x)\n        x = self.ada1(x, w)\n        x = self.activation(x)\n        if noise_inject:\n            x = x + torch.randn_like(x) * 0.1\n\n        x = self.conv2(x)\n        x = self.ada2(x, w)\n        x = self.activation(x)\n        if noise_inject:\n            x = x + torch.randn_like(x) * 0.1\n\n        x = self.conv3(x)\n        x = self.ada3(x, w)\n        x = self.activation(x)\n        if noise_inject:\n            x = x + torch.randn_like(x) * 0.1\n\n        x = self.conv4(x)\n        x = self.ada4(x, w)\n        x = self.activation(x)\n        if noise_inject:\n            x = x + torch.randn_like(x) * 0.1\n\n        x = self.conv5(x)\n        x = self.ada5(x, w)\n        x = self.activation(x)\n        if noise_inject:\n            x = x + torch.randn_like(x) * 0.1\n\n        x = self.conv6(x)\n        x = self.activation(x)  \n        x = self.conv7(x)\n        return self.tanh(x)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def compute_gaussian_parameters(latents):\n    \"\"\"\n    Computes the mean and covariance of the latent space for slice relationships.\n    \"\"\"\n    mean_vector = np.mean(latents, axis=0)\n    cov_matrix = np.cov(np.array(latents).T)\n    return mean_vector, cov_matrix\n\n\ndef sample_new_latents(mean, cov, num_samples):\n    \"\"\"\n    Samples new latent variables based on the Gaussian distribution.\n    \"\"\"\n    return np.random.multivariate_normal(mean, cov, size=num_samples)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import nibabel as nib\nfrom torch.utils.data import Dataset, DataLoader\n\n\nclass GliomaBraTSDataset(Dataset):\n    def __init__(self, root_dir, transform=None):\n        self.root_dir = root_dir\n        self.transform = transform\n        self.data = []\n\n        for patient_folder in os.listdir(root_dir):\n            patient_path = os.path.join(root_dir, patient_folder)\n            if os.path.isdir(patient_path):\n                t1c_path = [file for file in os.listdir(patient_path) if 't1c.nii' in file]\n                if t1c_path:\n                    self.data.append(os.path.join(patient_path, t1c_path[0]))\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        file_path = self.data[idx]\n        volume = nib.load(file_path).get_fdata()\n        \n        # Normalize real volumes to [-1, 1]\n        volume = (volume - volume.min()) / (volume.max() - volume.min())  # Normalize to [0, 1]\n        volume = (volume * 2) - 1  # Normalize to [-1, 1]\n        \n        volume = torch.tensor(volume, dtype=torch.float32).unsqueeze(0)  # Add channel dim\n        if self.transform:\n            volume = self.transform(volume)\n        return volume\n\nclass Discriminator3D(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.model = nn.Sequential(\n            nn.Conv3d(1, 64, kernel_size=4, stride=2, padding=1),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv3d(64, 128, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm3d(128),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv3d(128, 256, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm3d(256),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv3d(256, 512, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm3d(512),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv3d(512, 1, kernel_size=4, stride=1, padding=0),\n        )\n\n    def forward(self, x):\n        return self.model(x).view(-1)  # Flatten output to scalar\n\n\ndef discriminator_loss(real, fake):\n    return torch.mean((real - 1) ** 2) + torch.mean(fake ** 2)\n\ndef generator_loss(fake):\n    return torch.mean((fake - 1) ** 2)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train(generator, dataloader, num_epochs, device):\n    generator.to(device)\n    optimizer = torch.optim.Adam(generator.parameters(), lr=0.0002, betas=(0.0, 0.99))\n    loss_fn = nn.MSELoss()\n\n    for epoch in range(num_epochs):\n        for real_volumes in dataloader:\n            real_volumes = real_volumes.to(device)\n\n            # Generate fake volumes\n            z = torch.randn(real_volumes.size(0), generator.mapping.latent_dim).to(device)\n            labels = torch.randint(0, 2, (real_volumes.size(0),)).to(device)\n            fake_volumes = generator(z, labels)\n\n            # Compute loss\n            loss = loss_fn(fake_volumes, real_volumes)\n\n            # Backpropagation\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfrom torchvision.transforms import Compose\nfrom torch.utils.data import DataLoader\n\ntransform = Compose([])\n\n# Initialize the dataset and dataloader\nroot_dir = \"/kaggle/input/brats-africa/PKG - BraTS-Africa/BraTS-Africa/95_Glioma\"  # Replace with your dataset directory\ndataset = GliomaBraTSDataset(root_dir=root_dir, transform=transform)\ndataloader = DataLoader(dataset, batch_size=4, shuffle=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nlatent_dim = 512\nstyle_dim = 512\nnum_classes = 2  # Adjust based on dataset labels\n\ngenerator = Generator3D(latent_dim=latent_dim, style_dim=style_dim, num_classes=num_classes).to(device)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"latent_space = []\n\n# Generate latent representations for the dataset\nfor real_volumes in dataloader:\n    real_volumes = real_volumes.to(device)\n    z = torch.randn(real_volumes.size(0), latent_dim).to(device)\n    labels = torch.randint(0, 2, (real_volumes.size(0),)).to(device)\n\n    # Store latent vectors\n    with torch.no_grad():\n        latents = generator.mapping(z, labels).cpu().numpy()\n        latent_space.extend(latents)\n\n# Compute Gaussian parameters\nlatent_mean, latent_cov = compute_gaussian_parameters(latent_space)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch.optim as optim\n\n# Hyperparameters\nlatent_dim = 512\nstyle_dim = 512\nnum_classes = 2\nlearning_rate = 0.0002\nnum_epochs = 50\n\ndiscriminator = Discriminator3D().to(device)\noptimizer_d = torch.optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n\n# Initialize model and optimizer\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ngenerator = Generator3D(latent_dim, style_dim, num_classes).to(device)\noptimizer = optim.Adam(generator.parameters(), lr=learning_rate, betas=(0.0, 0.99))\nloss_fn = nn.MSELoss()\n\nfor epoch in range(num_epochs):\n    for real_volumes in dataloader:\n        real_volumes = real_volumes.to(device)\n\n        # Preprocess real volumes to match discriminator input shape\n        real_volumes_resized = F.interpolate(real_volumes, size=(128, 128, 128), mode='trilinear', align_corners=False)\n\n        # Generate fake volumes\n        z = torch.randn(real_volumes.size(0), latent_dim).to(device)\n        labels = torch.randint(0, num_classes, (real_volumes.size(0),)).to(device)\n        fake_volumes = generator(z, labels)\n\n        print(f\"Real volumes resized shape: {real_volumes_resized.shape}\")\n        print(f\"Fake volumes shape: {fake_volumes.shape}\")\n\n        # Check shapes\n        assert real_volumes_resized.shape == fake_volumes.shape, \"Shape mismatch between real and fake volumes\"\n\n        # Train Discriminator\n        optimizer_d.zero_grad()\n        real_validity = discriminator(real_volumes_resized)\n        fake_validity = discriminator(fake_volumes.detach())\n        d_loss = torch.mean((real_validity - 1) ** 2) + torch.mean(fake_validity ** 2)  # LSGAN Loss\n        d_loss.backward()\n        optimizer_d.step()\n\n        # Train Generator\n        optimizer_g.zero_grad()\n        fake_validity = discriminator(fake_volumes)\n        g_loss = torch.mean((fake_validity - 1) ** 2)  # LSGAN Loss\n        g_loss.backward()\n        optimizer_g.step()\n\n    print(f\"Epoch {epoch+1}/{num_epochs}, D Loss: {d_loss.item():.4f}, G Loss: {g_loss.item():.4f}\")\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(generator)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Sample new latent variables from Gaussian distribution\nnum_samples = 10\nsampled_latents = sample_new_latents(latent_mean, latent_cov, num_samples)\n\n# Convert sampled latents to PyTorch tensors\nsampled_latents = torch.tensor(sampled_latents, dtype=torch.float32).to(device)\nlabels = torch.randint(0, 2, (num_samples,)).to(device)\n\n# Generate new 3D MRI volumes\nwith torch.no_grad():\n    generated_volumes = generator(sampled_latents, labels)\n\n# Visualize or save generated volumes\ngenerated_volumes = generated_volumes.cpu().numpy()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Visualize slices from a generated 3D volume\nfor i, volume in enumerate(generated_volumes):\n    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n\n    # Axial, coronal, and sagittal slices\n    axes[0].imshow(volume[0, :, :, volume.shape[3] // 2], cmap='gray')  # Axial\n    axes[0].set_title(f\"Volume {i + 1} - Axial\")\n\n    axes[1].imshow(volume[0, :, volume.shape[2] // 2, :], cmap='gray')  # Coronal\n    axes[1].set_title(f\"Volume {i + 1} - Coronal\")\n\n    axes[2].imshow(volume[0, volume.shape[1] // 2, :, :], cmap='gray')  # Sagittal\n    axes[2].set_title(f\"Volume {i + 1} - Sagittal\")\n\n    plt.tight_layout()\n    plt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}